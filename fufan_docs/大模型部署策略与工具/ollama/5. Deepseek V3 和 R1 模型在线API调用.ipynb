{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Deepseek企业级Agent项目开发实战</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Part 5. Deepseek V3 和 R1 模型在线API调用</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;除了本地部署`DeepSeek` 模型外，我们还可以通过`DeepSeek` 提供的在线`API`接口进行调用。这是一种更加轻量级、灵活的使用方式。本节内容主要介绍如何使用`Deepseek V3` 和 `R1` 模型进行在线`API`调用满血版`DeepSeek v3 & r1` 模型。 \n",
    "\n",
    "&emsp;&emsp;一种最简单的理解方法是：前几节课我们通过`ollama`在本地部署的了`DeepSeek R1`模型，最终的目的是能够提供一个类似于`http:localhost:11434/v1/chat/completions`的接口，然后我们就可以像调用`OpenAI`的接口一样调用`DeepSeek`的接口了。这个过程需要我们有本地的`GPU`资源，然后通过`ollama`来启动和管理模型。 `DeepSeek` 的在线API接口，则不需要我们自己用本地的`GPU`资源去部署，而是由服务商部署好模型，然后我们通过注册账号，获取`API Key`，然后就也可以像调用`OpenAI`的接口一样调用`DeepSeek`的接口。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 注册deepseek账号\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果想访问`DeepSeek`的在线`API`接口，首先我们需要注册一个`deepseek`的账号，然后去获取到一个有效的`API Key`。官方的`DeepSeek` 的`API`服务地址是：https://platform.deepseek.com/usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202502141003689.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后充值，按照如下方式获取`API Key`即可，非常简单。`DeepSeek`的`API`接口是按照`token`来收费的，不过现阶段因为服务器资源紧张，`DeepSeek`官方暂时停止了充值服务，大家可以等待服务恢复。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202502141005828.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 2. DeepSeek v3 调用指南"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`DeepSeek API` 使用与 `OpenAI` 兼容的 `API` 格式，如下是`OpenAI`的`API`调用格式：\n",
    "\n",
    "```python\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI()\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    print(completion.choices[0].message)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;因此，需要在`OpenAI`的`API`调用格式的基础上，将`OpenAI`的`base_url`替换为`DeepSeek`的`endpoint`,以及将`model`替换为`DeepSeek`的`model`。其中 `DeepSeek v3` 的`model`名称是：`deepseek-chat`，即："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **非流式输出**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以！我很乐意为你解释什么是“大模型”。\n",
      "\n",
      "这是一个非常核心的概念，可以说是当前人工智能浪潮的基石。\n",
      "\n",
      "简单来说：\n",
      "\n",
      "**大模型是指在海量数据上训练的、参数规模巨大（通常达到数十亿甚至万亿级别）的深度学习模型。它们通常基于“Transformer”架构，具备强大的通用任务处理和内容生成能力。**\n",
      "\n",
      "为了让你更好地理解，我们来拆解一下这个定义：\n",
      "\n",
      "---\n",
      "\n",
      "### 1. 核心特征：“大”在哪里？\n",
      "\n",
      "*   **数据量大：** 它们不是在几千、几万条数据上训练的，而是在**整个互联网规模**的文本、图像、代码等数据上进行训练。这包括了维基百科、书籍、新闻文章、论坛、网站等等。\n",
      "*   **参数规模大：** “参数”是模型从数据中学到的“知识”或“规律”的载体。你可以把它想象成模型大脑中的**神经元连接数量**。\n",
      "    *   当一个模型的参数达到**数十亿（Billion）** 或**万亿（Trillion）** 级别时，它就被认为是“大模型”。\n",
      "    *   例如，GPT-3有1750亿个参数。\n",
      "*   **算力需求大：** 训练这样的模型需要巨大的计算资源，通常需要成千上万个高性能GPU/TPU连续运算数周甚至数月，成本极其高昂。\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 关键能力：能做什么？\n",
      "\n",
      "大模型最引人注目的能力是**涌现能力** 和**通用性**。\n",
      "\n",
      "*   **涌现能力：** 当模型规模达到一定程度时，它会表现出在小型模型中没有的、意想不到的能力。比如：\n",
      "    *   **理解和生成自然语言：** 能进行流畅的对话、写文章、总结内容、翻译语言。\n",
      "    *   **逻辑推理：** 解决简单的数学问题、进行常识推理。\n",
      "    *   **代码生成：** 根据描述自动编写代码、调试程序。\n",
      "    *   **知识问答：** 基于训练时学到的海量知识回答问题。\n",
      "\n",
      "*   **通用性：** 与以往“一个模型解决一个任务”（如专门用于识别的模型）不同，大模型是一个**通才**。同一个模型，无需改变结构，就能通过简单的文字指令（即“提示”）来完成千变万化的任务。\n",
      "    *   你可以让它“写一首关于夏天的诗”，然后下一秒让它“把上面这首诗翻译成英语”，再下一秒让它“用表格总结这首诗的特点”。\n",
      "\n",
      "---\n",
      "\n",
      "### 3. 常见类型：\n",
      "\n",
      "大模型主要分为以下几类：\n",
      "\n",
      "*   **大语言模型：** 这是目前最主流的大模型，专门处理和生成文本。\n",
      "    *   **代表：** OpenAI的GPT系列（如ChatGPT）、Google的PaLM系列（如Bard的背景模型）、Anthropic的Claude、Meta的LLaMA。\n",
      "*   **多模态大模型：** 不仅能处理文本，还能理解和生成图像、音频、视频等多种信息。\n",
      "    *   **代表：** OpenAI的GPT-4V（能“看懂”图片）、Google的Gemini。\n",
      "\n",
      "---\n",
      "\n",
      "### 打个比方\n",
      "\n",
      "你可以把一个传统的小模型想象成一个**专业的工具**，比如一把专门拧螺丝的螺丝刀。而大模型则像一个**万能工具箱**，它里面有无数的工具零件（参数），并且配备了一个极其聪明的**机器人（核心算法）**。你只需要用语言告诉这个机器人你想做什么（“提示”），它就能立刻从工具箱里找出或组合出合适的工具，帮你完成任务——无论是拧螺丝、钉钉子还是切割材料。\n",
      "\n",
      "---\n",
      "\n",
      "### 总结\n",
      "\n",
      "**大模型**是人工智能领域的一个范式转变，它通过“大力出奇迹”的方式，创造了具备强大通用性和对话能力的AI系统。它们正在成为推动各行各业变革的基础技术，也是你我今天能够进行如此自然对话的背后原因。\n",
      "\n",
      "希望这个解释对你有帮助！如果你对某个特定方面（比如Transformer架构、训练过程等）还想了解更多，随时可以再问我。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=\"sk-f9428eb2c924426783428c5b465542de\", base_url=\"https://api.deepseek.com/v1/\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",   \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一位乐于助人的AI助手\"},\n",
    "        {\"role\": \"user\", \"content\": \"请问什么是大模型？\"},\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **流式输出**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然！很乐意为您解释什么是“大模型”。\n",
      "\n",
      "这是一个非常核心和热门的概念。我们可以从几个层面来理解它：\n",
      "\n",
      "### 一、核心定义：什么是大模型？\n",
      "\n",
      "**大模型**，通常指的是**大型语言模型**，它是一种基于海量数据训练的、参数规模极其巨大的深度学习模型。\n",
      "\n",
      "我们可以把它拆解成三个关键词来理解：\n",
      "\n",
      "1.  **大**\n",
      "    *   **数据量大**：使用来自互联网的数千亿甚至数万亿的单词、图像、代码等进行训练，几乎涵盖了人类知识的方方面面。\n",
      "    *   **参数规模大**：“参数”是模型从数据中学到的内部知识和规则的数量。大模型的参数动辄达到百亿、千亿甚至万亿级别。参数越多，模型能理解和记忆的信息就越复杂。\n",
      "    *   **算力消耗大**：训练这样的模型需要成千上万的高性能GPU/TPU工作数周甚至数月，消耗巨大的电力和社会资源。\n",
      "\n",
      "2.  **语言模型**\n",
      "    *   它的核心能力是理解和生成人类语言。本质上，它是一个“下一个词预测器”。当你输入一段话（提示），它会根据上文，计算出下一个最可能出现的词是什么，并以此类推，生成完整的句子、段落甚至文章。\n",
      "\n",
      "3.  **基础模型**\n",
      "    *   这是大模型的另一个重要特性。它们首先在广泛的数据上进行“预训练”，获得通用的语言和世界知识。然后，可以通过“微调”等技术，快速适配到各种具体的下游任务（如法律咨询、医疗问答、写代码等），而无需从头开始训练。\n",
      "\n",
      "**简单来说，你可以把大模型想象成一个博览群书、记忆力超群的“超级大脑”。它通过学习海量的人类知识，掌握了语言的内在规律和世界的逻辑，从而能够与人进行对话、解答问题、创作内容。**\n",
      "\n",
      "---\n",
      "\n",
      "### 二、大模型能做什么？（核心能力）\n",
      "\n",
      "大模型展现出令人惊叹的多种能力，主要包括：\n",
      "\n",
      "*   **自然语言理解与生成**：流畅地进行多轮对话、翻译语言、总结长篇文章、撰写邮件、报告、故事、诗歌等。\n",
      "*   **知识问答与推理**：基于其庞大的知识库回答各种事实性问题，并能进行简单的逻辑推理和常识判断。\n",
      "*   **代码生成与理解**：根据自然语言描述生成代码、解释代码、调试程序、在不同编程语言间进行转换。\n",
      "*   **多模态能力**：最新的模型不仅能处理文本，还能理解和生成图像、音频、视频。例如，根据文字描述生成图片（如DALL-E、Midjourney），或描述一张图片的内容。\n",
      "\n",
      "---\n",
      "\n",
      "### 三、典型代表\n",
      "\n",
      "你最可能接触过的大模型包括：\n",
      "\n",
      "*   **GPT系列**：由OpenAI开发，例如ChatGPT背后的GPT-3.5、GPT-4等，是当前最著名的代表。\n",
      "*   **Gemini**：由Google开发，原生支持多模态。\n",
      "*   **Claude**：由Anthropic开发，注重安全性和长上下文能力。\n",
      "*   **Llama**：由Meta开发，是一个开源的大模型系列，推动了整个行业的发展。\n",
      "*   **文心一言**：由百度开发的中国代表性大模型。\n",
      "*   **通义千问**：由阿里巴巴开发。\n",
      "\n",
      "---\n",
      "\n",
      "### 四、重要意义与挑战\n",
      "\n",
      "**重要意义：**\n",
      "*   **技术范式变革**：大模型正成为新一代的通用技术平台，类似于当年的PC和互联网，将深刻改变各行各业。\n",
      "*   **降低AI应用门槛**：开发者无需从零开始训练专业模型，只需基于大模型进行微调或通过API调用，就能快速开发出强大的AI应用。\n",
      "*   **推动生产力革命**：在内容创作、编程辅助、客户服务、教育、科研等领域，大模型能极大提升效率。\n",
      "\n",
      "**面临的挑战：**\n",
      "*   **“幻觉”问题**：模型可能会自信地生成看似合理但完全是错误或编造的信息。\n",
      "*   **偏见与有害内容**：训练数据中的社会偏见可能被模型学习并放大。\n",
      "*   **安全与滥用**：可能被用于生成虚假信息、网络钓鱼邮件或恶意代码。\n",
      "*   **高成本与资源消耗**：训练和部署成本极高，导致技术集中在少数大公司手中。\n",
      "*   **理解与可控性**：模型的决策过程像一个“黑箱”，难以完全理解和控制。\n",
      "\n",
      "### 总结\n",
      "\n",
      "**大模型是当前人工智能领域最重大的突破之一，它是一个通过海量数据和算力训练出来的、具备强大语言理解和生成能力的通用人工智能系统。** 它不仅是更聪明的聊天机器人，更是推动社会迈向“智能增强”时代的关键引擎，虽然它也带来了诸多需要解决的挑战。\n",
      "\n",
      "希望这个解释能帮助你全面地理解“大模型”！如果你对某个特定方面（比如它是如何训练的，或者具体应用）感兴趣，我们可以继续深入探讨。"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=\"sk-f9428eb2c924426783428c5b465542de\", base_url=\"https://api.deepseek.com/v1/\")\n",
    "\n",
    "\n",
    "# 调用聊天接口，启用流式输出\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",  # 根据实际情况替换模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一位乐于助人的AI助手\"},\n",
    "        {\"role\": \"user\", \"content\": \"请问什么是大模型？\"},\n",
    "    ],\n",
    "    temperature=1.0,\n",
    "    stream=True  # 启用流式输出\n",
    "\n",
    ")\n",
    "\n",
    "try:\n",
    "    # 处理流式响应\n",
    "    for chunk in response:\n",
    "        if chunk.choices and chunk.choices[0].delta.content:\n",
    "             print(chunk.choices[0].delta.content, end='', flush=True)                     \n",
    "except Exception as e:\n",
    "    print(\"发生错误:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DeepSeek R1 调用指南\n",
    "\n",
    "&emsp;&emsp;`DeepSeek R1` 的`API`调用与`DeepSeek v3`的`API`调用类似，只需要将`model`替换为`DeepSeek R1`的`model`即可。其中 `DeepSeek R1` 的`model`名称是：`deepseek-reasoner`，即：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **非流式输出**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然，我很乐意为您解释什么是“大模型”。\n",
      "\n",
      "“大模型”是**大型语言模型** 的简称，它是当今人工智能领域最令人兴奋和最具影响力的技术之一。您可能听过的ChatGPT、文心一言、文心一格等，其核心就是大模型。\n",
      "\n",
      "我们可以从几个层面来理解它：\n",
      "\n",
      "### 1. 核心定义\n",
      "\n",
      "大模型是一个**基于海量数据训练的、包含数百亿甚至数千亿参数的深度学习模型**。它本质上是一个极其复杂的“数学函数”或“概率预测机器”。\n",
      "\n",
      "*   **“大”体现在哪里？**\n",
      "    *   **参数数量巨大**：参数是模型在训练过程中学到的“内部知识”。你可以把它想象成人类大脑中的神经连接。参数越多，模型能理解和记忆的信息就越复杂、越细微。\n",
      "    *   **训练数据海量**：大模型通常在互联网级别的海量文本、图像、代码等数据上进行训练，这使其具备了极其广博的“知识面”。\n",
      "    *   **算力消耗惊人**：训练一个大模型需要成千上万个高性能GPU/芯片连续工作数周甚至数月，消耗巨大的电力，成本极高。\n",
      "\n",
      "### 2. 它的基本能力是什么？\n",
      "\n",
      "大模型的核心能力是 **“基于上文，生成下文”** ，也就是**概率预测**。\n",
      "\n",
      "当你输入一段话（称为“提示”或“Prompt”）时，模型会根据它从海量数据中学到的规律，计算出下一个最可能出现的词是什么，然后一个词一个词地生成，直到形成一段完整的、通顺的回答。\n",
      "\n",
      "基于这个核心能力，大模型展现出了多种令人惊叹的才能：\n",
      "\n",
      "*   **自然语言理解与生成**：流畅地对话、撰写文章、写诗、写邮件、总结长文档。\n",
      "*   **知识问答**：像一个博学的专家一样回答各种事实性问题（但需要注意，它有时会“一本正经地胡说八道”，即产生“幻觉”）。\n",
      "*   **代码生成与理解**：根据描述编写代码、解释代码、调试程序。\n",
      "*   **多模态能力**：新一代的大模型不仅能处理文本，还能理解和生成图像、音频、视频。例如，你描述一个画面，它就能生成对应的图片。\n",
      "\n",
      "### 3. 一个简单的比喻\n",
      "\n",
      "你可以把大模型想象成一个**博览群书、天赋异禀的“超级实习生”**。\n",
      "\n",
      "*   它读完了互联网上几乎所有的公开书籍、文章、代码和网页。\n",
      "*   它拥有极强的“模仿”和“举一反三”的能力。你给它看几个例子（这叫做“小样本学习”），它就能模仿出类似风格的内容。\n",
      "*   但它没有真实的意识、情感和个人经历。它的所有回答都基于它“读过”的内容的统计规律。\n",
      "*   它有时会犯错，会编造信息，也可能学到训练数据中存在的一些偏见和不准确的内容。\n",
      "\n",
      "### 4. 常见的大模型例子\n",
      "\n",
      "*   **GPT系列**：由OpenAI开发，如GPT-3.5、GPT-4，是ChatGPT背后的模型。\n",
      "*   **文心大模型**：由百度开发的中文大模型。\n",
      "*   **通义千问**：由阿里巴巴开发。\n",
      "*   **LLaMA系列**：由Meta（Facebook）开发的开源模型。\n",
      "*   **Gemini**：由Google开发的多模态大模型。\n",
      "*   **Stable Diffusion / Midjourney**：它们是专注于图像生成的“大模型”。\n",
      "\n",
      "### 总结\n",
      "\n",
      "**大模型**是一种**基础性的人工智能技术**，它通过在海量数据上训练出超大规模的参数，获得了强大的通用任务处理能力，尤其是理解和生成人类语言的能力。它正在深刻地改变我们与计算机交互的方式，并推动各行各业的智能化变革。\n",
      "\n",
      "希望这个解释能帮助您理解！如果您对某个特定方面（比如它是如何训练的、有哪些具体应用等）还有疑问，我很乐意继续为您解答。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=\"sk-f9428eb2c924426783428c5b465542de\", base_url=\"https://api.deepseek.com/v1/\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-reasoner\",   # 注意：这里是因为我购买的 deepseek 服务上要求提供的模型名称是 DeepSeek-R1，大家根据自己的情况进行替换\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一位乐于助人的AI助手\"},\n",
    "        {\"role\": \"user\", \"content\": \"请问什么是大模型？\"},\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **流式输出**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然！这是一个关于“大模型”非常全面的解释，希望能帮助你彻底理解它。\n",
      "\n",
      "---\n",
      "\n",
      "### 什么是大模型？\n",
      "\n",
      "**大模型**，全称是**大型语言模型**，是一种基于海量数据训练的、参数规模巨大的深度学习模型。你可以把它想象成一个吸收了互联网上绝大部分公开知识的“超级大脑”。\n",
      "\n",
      "它的核心特点是 **“大”** ，主要体现在三个方面：\n",
      "\n",
      "1.  **参数规模大**：参数是模型从数据中学到的内部变量，决定了模型如何处理信息。大模型的参数量通常达到**数十亿、数百亿甚至万亿级别**。参数越多，模型能捕捉和存储的知识与规律就越复杂。\n",
      "2.  **训练数据量大**：它们使用来自互联网的海量文本和代码进行训练，包括书籍、文章、百科、网页、论坛对话等，数据量可达TB级别。\n",
      "3.  **计算资源消耗大**：训练这样的模型需要庞大的计算集群（成千上万的高性能GPU/TPU），耗时数周甚至数月，耗资巨大。\n",
      "\n",
      "### 大模型是如何工作的？\n",
      "\n",
      "简单来说，大模型的核心任务是 **“预测下一个词”**。\n",
      "\n",
      "*   在训练时，它会被输入一段文本（比如“今天天气很好，我们去…”），然后模型的任务是预测最可能出现的下一个词（比如“公园”、“散步”）。\n",
      "*   通过在海量数据上重复这个过程，模型不仅学会了语法和词汇，还学会了事实、逻辑推理、不同语言的对应关系，甚至不同行文的风格和语调。\n",
      "*   当你向它提问时，它实际上是在根据你的输入，以极高的概率，一个词一个词地“生成”最合理、最连贯的后续文本。\n",
      "\n",
      "### 大模型的核心能力\n",
      "\n",
      "经过训练后，大模型展现出了一些令人惊叹的能力：\n",
      "\n",
      "1.  **生成能力**：能够创作文章、故事、诗歌、邮件、代码等。\n",
      "2.  **理解能力**：能够阅读、总结、翻译复杂的文本。\n",
      "3.  **推理能力**：具备一定的逻辑推理和解决复杂问题的能力（例如解数学题、分析原因）。\n",
      "4.  **对话能力**：能够进行多轮、有上下文联系的自然对话。\n",
      "5.  **代码能力**：能够编写、解释、调试不同编程语言的代码。\n",
      "\n",
      "### 著名的例子\n",
      "\n",
      "你很可能已经接触过一些著名的大模型：\n",
      "\n",
      "*   **GPT系列**：由OpenAI开发，ChatGPT就是基于GPT模型构建的对话应用。\n",
      "*   **Gemini**：由Google开发，是其对抗GPT系列的核心模型。\n",
      "*   **LLaMA**：由Meta开发，是一个开源的模型系列，推动了业界发展。\n",
      "*   **文心一言**：由百度开发的中文大模型。\n",
      "*   **通义千问**：由阿里巴巴开发的中文大模型。\n",
      "\n",
      "### 与大模型相关的关键概念：基础模型\n",
      "\n",
      "**基础模型** 是与大模型紧密相连的一个概念。它特指那些在广泛数据上训练出来的、可以作为“基础”来适应各种下游任务的巨大模型。**几乎所有的大模型都属于基础模型**，但基础模型经过“微调”后，可以变成专注于特定领域（如医疗、法律、客服）的、更小更专业的模型。\n",
      "\n",
      "可以理解为：**基础模型是“通才”，而基于它微调出来的模型是“专才”。**\n",
      "\n",
      "### 大模型的局限与挑战\n",
      "\n",
      "大模型并非万能，也存在明显的问题：\n",
      "\n",
      "*   **“幻觉”**：它可能会自信地生成完全错误或虚构的信息。\n",
      "*   **知识滞后**：它的知识截止于训练数据的时间点，无法获取最新信息（除非通过其他技术手段连接网络）。\n",
      "*   **偏见与有害内容**：训练数据中的偏见和不良内容可能会被模型学习并放大。\n",
      "*   **计算成本高昂**：训练和部署的成本非常高。\n",
      "*   **缺乏真正的理解**：它本质上是统计和模式匹配，并不像人类一样真正“理解”语义。\n",
      "\n",
      "### 总结\n",
      "\n",
      "总而言之，**大模型是当前人工智能领域的前沿，是一种通过在海量数据上训练而成的、具有强大内容生成和理解能力的巨型人工智能系统。** 它正在深刻地改变我们与信息交互的方式，并在内容创作、教育培训、代码编程、客户服务等多个领域展现出巨大的应用潜力。\n",
      "\n",
      "希望这个解释对你有帮助！如果你对某个具体方面（比如它是如何训练的，或者某个特定模型）还有疑问，欢迎继续提问！"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"sk-f9428eb2c924426783428c5b465542de\", base_url=\"https://api.deepseek.com/v1/\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-reasoner\",    \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一位乐于助人的AI助手\"},\n",
    "        {\"role\": \"user\", \"content\": \"请问什么是大模型？\"},\n",
    "    ],\n",
    "    stream=True,\n",
    "    temperature=0.6,\n",
    ")\n",
    "\n",
    "try:\n",
    "    # 处理流式响应\n",
    "    for chunk in response:\n",
    "        if chunk.choices and chunk.choices[0].delta.content:\n",
    "             print(chunk.choices[0].delta.content, end='', flush=True)                     \n",
    "except Exception as e:\n",
    "    print(\"发生错误:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里需要注意的是：`DeepSeek R1` 现在还不支持`Function Calling` 和 `Json Output` 格式化输出，所以目前还无法直接接入`Agent`构建工作流。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
