"""
vLLM æ™ºèƒ½å¯¹è¯è„šæœ¬
æä¾›äº¤äº’å¼å‘½ä»¤è¡Œç•Œé¢ï¼Œæ”¯æŒå¤šè½®å¯¹è¯ã€å†å²è®°å½•ã€æµå¼è¾“å‡ºç­‰åŠŸèƒ½

åŠŸèƒ½ç‰¹æ€§:
    - ğŸ¤– å¤šè½®å¯¹è¯ï¼Œè‡ªåŠ¨ç»´æŠ¤ä¸Šä¸‹æ–‡
    - ğŸ“ å¯¹è¯å†å²è®°å½•
    - ğŸ¨ å½©è‰²è¾“å‡ºï¼Œç¾åŒ–ç•Œé¢
    - ğŸ’¾ ä¿å­˜/åŠ è½½å¯¹è¯å†å²
    - âš™ï¸ åŠ¨æ€è°ƒæ•´å‚æ•°ï¼ˆæ¸©åº¦ã€é•¿åº¦ç­‰ï¼‰
    - ğŸ”„ æ”¯æŒæµå¼å’Œéæµå¼è¾“å‡º
    - ğŸ“Š æ˜¾ç¤º token ä½¿ç”¨ç»Ÿè®¡

ä½¿ç”¨æ–¹æ³•:
    python æ™ºèƒ½å¯¹è¯è„šæœ¬.py
    
    å‘½ä»¤åˆ—è¡¨:
        /help       - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        /clear      - æ¸…ç©ºå¯¹è¯å†å²
        /history    - æ˜¾ç¤ºå¯¹è¯å†å²
        /save       - ä¿å­˜å¯¹è¯åˆ°æ–‡ä»¶
        /load       - åŠ è½½å¯¹è¯å†å²
        /config     - æŸ¥çœ‹/ä¿®æ”¹é…ç½®
        /stream     - åˆ‡æ¢æµå¼è¾“å‡º
        /quit       - é€€å‡ºç¨‹åº

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025-10-08
"""

import sys
import os
import json
from datetime import datetime
from typing import List, Dict, Optional
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥ vllm_client
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from vllm_client import VLLMClient


# ============ é¢œè‰²è¾“å‡ºå·¥å…· ============

class Colors:
    """ANSI é¢œè‰²ä»£ç """
    RESET = '\033[0m'
    BOLD = '\033[1m'
    
    # å‰æ™¯è‰²
    BLACK = '\033[30m'
    RED = '\033[31m'
    GREEN = '\033[32m'
    YELLOW = '\033[33m'
    BLUE = '\033[34m'
    MAGENTA = '\033[35m'
    CYAN = '\033[36m'
    WHITE = '\033[37m'
    
    # äº®è‰²
    BRIGHT_RED = '\033[91m'
    BRIGHT_GREEN = '\033[92m'
    BRIGHT_YELLOW = '\033[93m'
    BRIGHT_BLUE = '\033[94m'
    BRIGHT_MAGENTA = '\033[95m'
    BRIGHT_CYAN = '\033[96m'


def print_colored(text: str, color: str = Colors.RESET, bold: bool = False):
    """å½©è‰²æ‰“å°"""
    prefix = Colors.BOLD if bold else ""
    print(f"{prefix}{color}{text}{Colors.RESET}")


def print_box(text: str, color: str = Colors.CYAN):
    """æ‰“å°å¸¦è¾¹æ¡†çš„æ–‡æœ¬"""
    lines = text.split('\n')
    max_len = max(len(line) for line in lines)
    
    print_colored("â”Œ" + "â”€" * (max_len + 2) + "â”", color)
    for line in lines:
        padding = " " * (max_len - len(line))
        print_colored(f"â”‚ {line}{padding} â”‚", color)
    print_colored("â””" + "â”€" * (max_len + 2) + "â”˜", color)


# ============ æ™ºèƒ½å¯¹è¯ç±» ============

class SmartChat:
    """æ™ºèƒ½å¯¹è¯ç®¡ç†å™¨"""
    
    def __init__(
        self,
        base_url: str = "http://localhost:9000",
        api_key: str = "muyu",
        model: str = "Medical_Qwen3_8B_Large_Language_Model",
        backend: str = 'openai'  # é»˜è®¤ä½¿ç”¨ openai åç«¯æ”¯æŒæµå¼è¾“å‡º
    ):
        """åˆå§‹åŒ–å¯¹è¯ç®¡ç†å™¨"""
        self.client = VLLMClient(
            base_url=base_url,
            api_key=api_key,
            model=model,
            backend=backend
        )
        
        self.messages: List[Dict[str, str]] = []
        self.config = {
            'max_tokens': 512,
            'temperature': 0.7,
            'top_p': 0.95,
            'stream': True,  # é»˜è®¤å¼€å¯æµå¼è¾“å‡º
            'backend': backend
        }
        
        self.history_dir = Path("chat_history")
        self.history_dir.mkdir(exist_ok=True)
        
        self.total_tokens_used = 0
    
    def add_message(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å†å²"""
        self.messages.append({
            "role": role,
            "content": content
        })
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.messages.clear()
        self.total_tokens_used = 0
        print_colored("âœ… å¯¹è¯å†å²å·²æ¸…ç©º", Colors.GREEN)
    
    def show_history(self):
        """æ˜¾ç¤ºå¯¹è¯å†å²"""
        if not self.messages:
            print_colored("ğŸ“­ æš‚æ— å¯¹è¯å†å²", Colors.YELLOW)
            return
        
        print_colored("\n" + "=" * 60, Colors.CYAN)
        print_colored("ğŸ“œ å¯¹è¯å†å²", Colors.CYAN, bold=True)
        print_colored("=" * 60, Colors.CYAN)
        
        for i, msg in enumerate(self.messages, 1):
            role = msg['role']
            content = msg['content']
            
            if role == 'user':
                print_colored(f"\n[{i}] ğŸ‘¤ ç”¨æˆ·:", Colors.BRIGHT_BLUE, bold=True)
                print(f"    {content}")
            else:
                print_colored(f"\n[{i}] ğŸ¤– åŠ©æ‰‹:", Colors.BRIGHT_GREEN, bold=True)
                print(f"    {content}")
        
        print_colored("\n" + "=" * 60 + "\n", Colors.CYAN)
    
    def save_history(self, filename: Optional[str] = None):
        """ä¿å­˜å¯¹è¯å†å²åˆ°æ–‡ä»¶"""
        if not self.messages:
            print_colored("âŒ æ²¡æœ‰å¯¹è¯å†å²å¯ä¿å­˜", Colors.RED)
            return
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"chat_{timestamp}.json"
        
        filepath = self.history_dir / filename
        
        data = {
            'timestamp': datetime.now().isoformat(),
            'config': self.config,
            'messages': self.messages,
            'total_tokens': self.total_tokens_used
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print_colored(f"âœ… å¯¹è¯å·²ä¿å­˜åˆ°: {filepath}", Colors.GREEN)
    
    def load_history(self, filename: str):
        """ä»æ–‡ä»¶åŠ è½½å¯¹è¯å†å²"""
        filepath = self.history_dir / filename
        
        if not filepath.exists():
            print_colored(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filepath}", Colors.RED)
            return
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.messages = data.get('messages', [])
            self.total_tokens_used = data.get('total_tokens', 0)
            
            print_colored(f"âœ… å·²åŠ è½½ {len(self.messages)} æ¡å¯¹è¯è®°å½•", Colors.GREEN)
        except Exception as e:
            print_colored(f"âŒ åŠ è½½å¤±è´¥: {e}", Colors.RED)
    
    def list_saved_chats(self):
        """åˆ—å‡ºå·²ä¿å­˜çš„å¯¹è¯"""
        files = sorted(self.history_dir.glob("chat_*.json"), reverse=True)
        
        if not files:
            print_colored("ğŸ“­ æ²¡æœ‰å·²ä¿å­˜çš„å¯¹è¯", Colors.YELLOW)
            return
        
        print_colored("\nğŸ“š å·²ä¿å­˜çš„å¯¹è¯:", Colors.CYAN, bold=True)
        for i, file in enumerate(files[:10], 1):  # åªæ˜¾ç¤ºæœ€è¿‘10ä¸ª
            size = file.stat().st_size
            mtime = datetime.fromtimestamp(file.stat().st_mtime)
            print(f"  {i}. {file.name} ({size} bytes, {mtime.strftime('%Y-%m-%d %H:%M')})")
        print()
    
    def show_config(self):
        """æ˜¾ç¤ºå½“å‰é…ç½®"""
        print_colored("\nâš™ï¸  å½“å‰é…ç½®:", Colors.CYAN, bold=True)
        print_colored("â”€" * 40, Colors.CYAN)
        for key, value in self.config.items():
            print(f"  {key:15s} = {value}")
        print_colored("â”€" * 40 + "\n", Colors.CYAN)
    
    def update_config(self, key: str, value):
        """æ›´æ–°é…ç½®"""
        if key not in self.config:
            print_colored(f"âŒ æœªçŸ¥é…ç½®é¡¹: {key}", Colors.RED)
            return
        
        # ç±»å‹è½¬æ¢
        try:
            if key == 'max_tokens':
                value = int(value)
            elif key in ['temperature', 'top_p']:
                value = float(value)
            elif key == 'stream':
                value = value.lower() in ['true', '1', 'yes', 'on']
            
            self.config[key] = value
            print_colored(f"âœ… å·²æ›´æ–°: {key} = {value}", Colors.GREEN)
        except ValueError as e:
            print_colored(f"âŒ æ— æ•ˆçš„å€¼: {e}", Colors.RED)
    
    def chat(self, user_input: str) -> str:
        """å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤"""
        self.add_message("user", user_input)
        
        try:
            if self.config['stream'] and self.config['backend'] == 'openai':
                # æµå¼è¾“å‡º
                print_colored("\nğŸ¤– åŠ©æ‰‹: ", Colors.BRIGHT_GREEN, bold=True)
                
                response_text = ""
                for chunk in self.client.chat_stream_with_history(
                    self.messages,
                    max_tokens=self.config['max_tokens'],
                    temperature=self.config['temperature'],
                    top_p=self.config['top_p']
                ):
                    print(chunk, end="", flush=True)
                    response_text += chunk
                
                print("\n")
                self.add_message("assistant", response_text)
                return response_text
            else:
                # éæµå¼è¾“å‡º
                response = self.client.chat_with_history(
                    self.messages,
                    max_tokens=self.config['max_tokens'],
                    temperature=self.config['temperature'],
                    top_p=self.config['top_p']
                )
                
                self.add_message("assistant", response)
                return response
        
        except Exception as e:
            print_colored(f"\nâŒ é”™è¯¯: {e}", Colors.RED)
            # ç§»é™¤å¤±è´¥çš„ç”¨æˆ·æ¶ˆæ¯
            self.messages.pop()
            return ""
    
    def close(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        self.client.close()


# ============ å‘½ä»¤å¤„ç† ============

def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    help_text = """
ğŸ¤– vLLM æ™ºèƒ½å¯¹è¯ç³»ç»Ÿ - å‘½ä»¤å¸®åŠ©

åŸºæœ¬å‘½ä»¤:
  /help           æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
  /quit, /exit    é€€å‡ºç¨‹åº
  /clear          æ¸…ç©ºå¯¹è¯å†å²
  /history        æ˜¾ç¤ºå®Œæ•´å¯¹è¯å†å²

å†å²ç®¡ç†:
  /save [æ–‡ä»¶å]  ä¿å­˜å¯¹è¯åˆ°æ–‡ä»¶ï¼ˆé»˜è®¤è‡ªåŠ¨å‘½åï¼‰
  /load <æ–‡ä»¶å>  åŠ è½½å¯¹è¯å†å²
  /list           åˆ—å‡ºå·²ä¿å­˜çš„å¯¹è¯

é…ç½®ç®¡ç†:
  /config                     æŸ¥çœ‹å½“å‰é…ç½®
  /config <å‚æ•°> <å€¼>         ä¿®æ”¹é…ç½®å‚æ•°
  /stream                     åˆ‡æ¢æµå¼è¾“å‡ºæ¨¡å¼

å¯é…ç½®å‚æ•°:
  max_tokens      æœ€å¤§ç”Ÿæˆtokenæ•° (é»˜è®¤: 512)
  temperature     æ¸©åº¦å‚æ•° 0-2 (é»˜è®¤: 0.7)
  top_p           top_pé‡‡æ · 0-1 (é»˜è®¤: 0.95)
  stream          æµå¼è¾“å‡º true/false (é»˜è®¤: false)

ç¤ºä¾‹:
  /config max_tokens 1000     è®¾ç½®æœ€å¤§tokenæ•°ä¸º1000
  /config temperature 0.5     è®¾ç½®æ¸©åº¦ä¸º0.5
  /save my_chat.json          ä¿å­˜å¯¹è¯
  /load my_chat.json          åŠ è½½å¯¹è¯

ä½¿ç”¨æŠ€å·§:
  â€¢ ç›´æ¥è¾“å…¥æ–‡æœ¬å³å¯å¼€å§‹å¯¹è¯
  â€¢ æ”¯æŒå¤šè½®å¯¹è¯ï¼Œè‡ªåŠ¨ç»´æŠ¤ä¸Šä¸‹æ–‡
  â€¢ ä½¿ç”¨ Ctrl+C å¯ä»¥ä¸­æ–­å½“å‰è¾“å‡º
  â€¢ æµå¼è¾“å‡ºéœ€è¦ OpenAI åç«¯æ”¯æŒ
"""
    print_colored(help_text, Colors.CYAN)


def show_welcome():
    """æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯"""
    welcome = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                            â•‘
â•‘          ğŸ¤– vLLM æ™ºèƒ½å¯¹è¯ç³»ç»Ÿ v1.0                         â•‘
â•‘                                                            â•‘
â•‘  åŸºäº vLLM çš„äº¤äº’å¼å¯¹è¯ç•Œé¢                                â•‘
â•‘  æ”¯æŒå¤šè½®å¯¹è¯ã€å†å²è®°å½•ã€æµå¼è¾“å‡ºç­‰åŠŸèƒ½                    â•‘
â•‘                                                            â•‘
â•‘  è¾“å…¥ /help æŸ¥çœ‹å‘½ä»¤å¸®åŠ©                                   â•‘
â•‘  è¾“å…¥ /quit é€€å‡ºç¨‹åº                                       â•‘
â•‘                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    print_colored(welcome, Colors.BRIGHT_CYAN, bold=True)


def process_command(chat: SmartChat, command: str) -> bool:
    """
    å¤„ç†å‘½ä»¤
    è¿”å› True è¡¨ç¤ºç»§ç»­è¿è¡Œï¼ŒFalse è¡¨ç¤ºé€€å‡º
    """
    parts = command.strip().split(maxsplit=1)
    cmd = parts[0].lower()
    args = parts[1] if len(parts) > 1 else ""
    
    if cmd in ['/quit', '/exit', '/q']:
        print_colored("\nğŸ‘‹ å†è§ï¼", Colors.BRIGHT_YELLOW, bold=True)
        return False
    
    elif cmd == '/help':
        show_help()
    
    elif cmd == '/clear':
        chat.clear_history()
    
    elif cmd == '/history':
        chat.show_history()
    
    elif cmd == '/save':
        filename = args if args else None
        chat.save_history(filename)
    
    elif cmd == '/load':
        if not args:
            print_colored("âŒ è¯·æŒ‡å®šæ–‡ä»¶å: /load <æ–‡ä»¶å>", Colors.RED)
        else:
            chat.load_history(args)
    
    elif cmd == '/list':
        chat.list_saved_chats()
    
    elif cmd == '/config':
        if not args:
            chat.show_config()
        else:
            config_parts = args.split(maxsplit=1)
            if len(config_parts) != 2:
                print_colored("âŒ ç”¨æ³•: /config <å‚æ•°> <å€¼>", Colors.RED)
            else:
                key, value = config_parts
                chat.update_config(key, value)
    
    elif cmd == '/stream':
        current = chat.config['stream']
        chat.config['stream'] = not current
        status = "å¼€å¯" if chat.config['stream'] else "å…³é—­"
        print_colored(f"âœ… æµå¼è¾“å‡ºå·²{status}", Colors.GREEN)
        
        if chat.config['stream'] and chat.config['backend'] != 'openai':
            print_colored("âš ï¸  è­¦å‘Š: æµå¼è¾“å‡ºéœ€è¦ OpenAI åç«¯", Colors.YELLOW)
    
    else:
        print_colored(f"âŒ æœªçŸ¥å‘½ä»¤: {cmd}", Colors.RED)
        print_colored("ğŸ’¡ è¾“å…¥ /help æŸ¥çœ‹å¯ç”¨å‘½ä»¤", Colors.YELLOW)
    
    return True


# ============ ä¸»ç¨‹åº ============

def main():
    """ä¸»å‡½æ•°"""
    show_welcome()
    
    # åˆå§‹åŒ–å¯¹è¯ç®¡ç†å™¨
    try:
        print_colored("ğŸ”„ æ­£åœ¨è¿æ¥ vLLM æœåŠ¡...", Colors.YELLOW)
        chat = SmartChat(
            base_url="http://localhost:9000",
            api_key="muyu",
            model="Medical_Qwen3_8B_Large_Language_Model",
            backend='openai'  # ä½¿ç”¨ openai åç«¯æ”¯æŒæµå¼è¾“å‡º
        )
        
        # æµ‹è¯•è¿æ¥
        models = chat.client.get_models()
        print_colored(f"âœ… è¿æ¥æˆåŠŸï¼å½“å‰æ¨¡å‹: {models[0]}", Colors.GREEN)
        print_colored("ğŸ’¬ æµå¼è¾“å‡º: å·²å¼€å¯", Colors.GREEN)
        print_colored("â”€" * 60 + "\n", Colors.CYAN)
        
    except Exception as e:
        print_colored(f"\nâŒ è¿æ¥å¤±è´¥: {e}", Colors.RED)
        print_colored("\nè¯·ç¡®ä¿:", Colors.YELLOW)
        print_colored("  1. vLLM æœåŠ¡å·²å¯åŠ¨", Colors.YELLOW)
        print_colored("  2. SSH éš§é“å·²å»ºç«‹ï¼ˆå¦‚éœ€è¦ï¼‰", Colors.YELLOW)
        print_colored("  3. ç«¯å£ 9000 å¯è®¿é—®", Colors.YELLOW)
        return
    
    # ä¸»å¾ªç¯
    try:
        while True:
            # è·å–ç”¨æˆ·è¾“å…¥
            try:
                user_input = input(f"{Colors.BRIGHT_BLUE}ğŸ‘¤ ä½ : {Colors.RESET}").strip()
            except EOFError:
                print()
                break
            
            if not user_input:
                continue
            
            # å¤„ç†å‘½ä»¤
            if user_input.startswith('/'):
                if not process_command(chat, user_input):
                    break
                continue
            
            # æ™®é€šå¯¹è¯
            try:
                if chat.config['stream'] and chat.config['backend'] == 'openai':
                    # æµå¼è¾“å‡ºå·²åœ¨ chat æ–¹æ³•ä¸­å¤„ç†
                    chat.chat(user_input)
                else:
                    # éæµå¼è¾“å‡º
                    response = chat.chat(user_input)
                    if response:
                        print_colored("\nğŸ¤– åŠ©æ‰‹: ", Colors.BRIGHT_GREEN, bold=True)
                        print(f"{response}\n")
            
            except KeyboardInterrupt:
                print_colored("\n\nâš ï¸  å·²ä¸­æ–­", Colors.YELLOW)
                continue
    
    except KeyboardInterrupt:
        print_colored("\n\nğŸ‘‹ ç¨‹åºå·²ä¸­æ–­", Colors.BRIGHT_YELLOW)
    
    finally:
        # æ¸…ç†èµ„æº
        chat.close()
        print_colored("\nâœ… èµ„æºå·²é‡Šæ”¾", Colors.GREEN)


if __name__ == "__main__":
    main()

