
启动 Qwen3-8B_Yi_Liao
vllm serve /root/autodl-tmp/vllm/zpeng1989/Medical_Qwen3_8B_Large_Language_Model \
    --host 0.0.0.0 \
    --port 9000 \
    --api-key muyu \
    --served-model-name Medical_Qwen3_8B_Large_Language_Model \
    --trust-remote-code \
    --max-model-len 32768 \
    --tensor-parallel-size 1


服务器到本地的映射：
    ssh -p 47055 -L 9000:localhost:9000 root@connect.nmb2.seetacloud.com
    输入密码


启动 Qwen3-4B
vllm serve /root/autodl-tmp/vllm/Qwen/Qwen3-4B \
    --served-model-name Qwen3-4B \
    --api_key muyu \
    --host 0.0.0.0 \
    --port 9000 \
    --trust_remote_code \
    --tensor_parallel_size 1





